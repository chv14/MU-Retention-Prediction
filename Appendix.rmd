---
title: "UNIVERSITY RETENTION PREDICTIVE MODELING"
author: "Chau Vu and Chloe Guo"
date:  "`r format(Sys.time(), '%B %d, %Y')`"

output: 
  rmarkdown::html_document:
    theme: lumen
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE, 
                      warning = FALSE,
                      message = FALSE)
```


Project introduction: We were given the data about Miami University students from 2009 to 2017. The large data set has several columns which contain information about each student. The goal of the project is using the provided data to build several models and select the best one to predict the retention rate for 2018 students data. Since the given data is messy, we performed some data wrangling and after that we split the data to build models. 

In this document, we will show the model comparison, data pre-processing, and modeling.
  
  
  
### Model Comparison {.tabset}
We will pick the Neural Network with terms from Random Forest model. According to the ROC table, the training ROC of this model is 0.6485425, the valid ROC is 0.6302581, which is the highest valid ROC among all 7 models. The training ROC of this model is also not too high, meaning that it seems to less overfit. We can see that this model has a consistent performance on both training and validation data.

*ROC Table*
```{r}
if(require(pacman) == FALSE) install.packages("pacman")
pacman::p_load(tidyverse, doParallel, nnet, caret, ranger, ROCR, gbm, xgboost, pROC, fastDummie)

training = readRDS("training.RDS")
valid = readRDS("valid.RDS")

step2<-readRDS("step2.RDS")
rforest<-readRDS("rforest.RDS")
gb.tree<-readRDS("gb.tree.RDS")
nnetFit<-readRDS("nnetFit.RDS")
nnetFit.rf<-readRDS("nnetFitRF.RDS")
lrstep<-readRDS("lrstep.RDS")
lrfull <-readRDS("lrfull.RDS")


# full logistic regression

plrfull_train<-predict.train(lrfull, type="prob") 
rft<-roc(training$Target, plrfull_train[,2])

plrfull<-predict.train(lrfull, newdata = valid, type="prob")
rf<-roc(valid$Target, plrfull[,2] )
df.full<-lrfull$finalModel$df.null-lrfull$finalModel$df.residual

#linear stepwise
pst<-predict(lrstep, type="prob")
rst<-roc(training$Target, pst[,2])

ps<-predict(lrstep, newdata=valid, type="prob")
rs<-roc(valid$Target, ps[,2])
df.step<-lrstep$finalModel$df.null-lrstep$finalModel$df.residual

#stepwise with interations
psit<-predict(step2, type="response")
rsit<-roc(training$Target, psit)
psi<-predict(step2, newdata=valid, type="response")
rsi<-roc(valid$Target, psi)
df.step2<-step2$df.null-step2$df.residual

#random forest
p.rforest.t<-predict(rforest, data=training, type="prob")
r.rft<-roc(training$Target,  p.rforest.t[,2])
r.rforest.auc.t<-r.rft$auc

p.rforest<-predict(rforest, newdata = valid, type="prob")
r.rf<-roc(valid$Target,  p.rforest[,2])
r.rforest.auc<-r.rf$auc

#boosted tree
p.gbtree<-predict(gb.tree, data=training, type="prob")
r.gbt<-roc(training$Target,  p.gbtree[,2])
r.gbtree.auc.t<-r.gbt$auc

p.gbtree<-predict(gb.tree, newdata=valid, type="prob")
r.gb<-roc(valid$Target,  p.gbtree[,2])
r.gbtree.auc<-r.gb$auc

#nn with logistic terms
p.nnet<-predict(nnetFit, data=training, type="prob")
r.nnt<-roc(training$Target,  p.nnet[,2])
r.nnet.auct<-r.nnt$auc

p.nnet<-predict(nnetFit, newdata=valid, type="prob")
r.nn<-roc(valid$Target,  p.nnet[,2])
r.nnet.auc<-r.nn$auc

#nn with random forest terms
p.nnet.rf<-predict(nnetFit.rf, data=training, type="prob")
r.nnrft<-roc(training$Target,  p.nnet.rf[,2])
r.nnet.rf.auct<-r.nnrft$auc

p.nnet.rf<-predict(nnetFit.rf, newdata=valid, type="prob")
r.nnrf<-roc(valid$Target,  p.nnet.rf[,2])
r.nnet.rf.auc<-r.nnrf$auc

library(knitr)
library(kableExtra)
results<-data.frame(
  Model=c("Full Logistic Regression", "LR Stepwise with Linear Terms", "LR Stepwise with Interations", "Random Forest", "Boosted Tree", "NN from LR", "NN from RF"),
  ROC.Training=c(rft$auc, rst$auc, rsit$auc,  r.rforest.auc.t, r.gbtree.auc.t, r.nnet.auct, r.nnet.rf.auct),
  ROC.Valid=c(rf$auc, rs$auc, rsi$auc,  r.rforest.auc, r.gbtree.auc, r.nnet.auc, r.nnet.rf.auc),
  Complexity=c(df.full, df.step, df.step2, "ntrees=1000", "ntrees=250", length(nnetFit$finalModel$wts), length(nnetFit.rf$finalModel$wts))
)
knitr::kable(results) %>% 
  kable_styling(full_width=F)

```

*Lift Chart*
```{r}

results<-data.frame(valid$Target,plrfull[,2], ps[,2], psi, p.rforest[,2], p.gbtree[,2], p.nnet[,2], p.nnet.rf[,2])

pred<-prediction(results$plrfull...2., results$valid.Target)
pred1<-prediction(results$ps...2., results$valid.Target)
pred2<-prediction(results$psi, results$valid.Target)
pred3<-prediction(results$p.rforest...2., results$valid.Target)
pred4<-prediction(results$p.gbtree...2., results$valid.Target)
pred5<-prediction(results$p.nnet...2., results$valid.Target)
pred6<-prediction(results$p.nnet.rf...2., results$valid.Target)

lift<-performance(pred, "lift", "rpp")
lift1<-performance(pred1, "lift", "rpp")
lift2<-performance(pred2, "lift", "rpp")
lift3<-performance(pred3, "lift", "rpp")
lift4<-performance(pred4, "lift", "rpp")
lift5<-performance(pred5, "lift", "rpp")
lift6<-performance(pred6, "lift", "rpp")

plot(lift,main="Lift chart", col="brown1", ylim=c(0,2))
plot(lift1, col="black", add=T)
plot(lift2, col="blue", add=T)
plot(lift3, col="chocolate2", add=T)
plot(lift4, col="chartreuse", add=T)
plot(lift5, col="darkmagenta", add=T)
plot(lift6, col="gold", add=T)

legend(0.6, 1, legend=c("Full Logistic Regression", "Stepwise Linear LR", "Stepwise Interation LR", "Random Forest", "Boosted Tree", "NN1", "NN2"),
       col=c("brown1", "black", "blue", "chocolate2", "chartreuse", "darkmagenta", "gold"), lty=1, cex=0.8)
```

*ROC Chart*
```{r}
roc<-list("Full Logistic Regression"=rf, "Stepwise Linear LR" = rs, "Stepwise Interation LR"=rsi, "Random Forest"=r.rf, 
          "Boosted Tree"=r.gb, "NN1"=r.nn, "NN2"=r.nnrf)
p<-ggroc(roc)
p+scale_color_discrete(name="Model")+theme_bw()+xlab("True Negative Rate")+ylab("True Positive Rate")

```



#### Cutoff Analysis
We use lift to find the cutoff probability.

```{r}
df<-data.frame(lift6@y.values,  lift6@alpha.values)
colnames(df)<-c("lift", "cutoff")

sub<-subset(df, lift>=2)
sub<-sub[order(sub$lift),]
sub[which.min(sub$cutoff),]
coords(r.nnrf,"best", ret="threshold")

results$Cut<-as.factor(ifelse(results$p.nnet.rf...2. > 0.09424767, "Yes", "No"))
head(results)

valid$p_Target <- results$Cut
write.csv(valid, "Update_Valid.csv")

confusionMatrix(data=results$Cut, reference=results$valid.Target, positive="Yes")
```



### Data Pre-Processing {.tabset}
  
#### Subset Data
We decided to subset the data and use data from 2010 - 2017 because when we looked at the variables by year, we saw that starting 2010, there are more variables than from 2005 - 2009. We want to choose less year and use more variables to better predict the future data.

```{r, eval=FALSE}
# Load Necessary Packages and Read in Data ----------------------------------------------
if(require(pacman) == FALSE) install.packages("pacman")
pacman::p_load(tidyverse, magrittr, DataExplorer, lubridate, dplyr, stringr, naniar, lares, fastDummies, readxl)

df = read.csv("domestic_data.csv", stringsAsFactors = T)
source("data summary.r")

# Filter Time Range ---------------------------------------------------------------------
df %<>% filter(DateFrom %in% (2010:2017))
```

#### Filter out International Students
Since we our focus is on the domestic students, we will filter out international students based on variables listed in the code.

```{r, eval=FALSE}
# Filter out International Students -----------------------------------------------------
# Filter out based on Application Type, Flag, Region, Race 
df %<>% filter(!ApplicationType %in% "OI" & # No missing value for ApplicationType
                      !InternationalFlag %in% c("International", "international") &
                      !MCFlag %in% "International" &
                      !USStateRegion %in% "International" &
                      !Race %in% "NC" &
                      !OneRace %in% c("NC", "Non-Resident Alien") &
                      !FullRace %in% "Non-Resident Alien")
df$ApplicationType <- droplevels(df$ApplicationType)
    
# Filter out based on visa type
df %<>% filter(((Visa.Type %in% c("RA - Resident Alien", "Asylee", "")) | is.na(Visa.Type)) &
               (VisaType %in% c("RA", "NV", "XX", "")) | is.na(VisaType))

# Filter out international students using TOEFL and IELTS
df %<>% filter_at(vars(TCP1, TCP2, TCP3, TCP4, TCPT, 	
                                   TIBL, TIBR, TIBS, TIBT, TIBW, 
                                   TOEFL.Listening, TOEFL.Reading, TOEFL.Speaking, 
                                   TOEFL.Structure.Written.Expression),
                                all_vars(is.na(.))) # all_vars(is.na(.)) means all the variables listed need to be NA

df %<>% filter_at(vars(IELL, IELO, IELR, IELS, IELW,
                       IELTS.Listening, IELTS.Overall.Band.Score, IELTS.Reading, IELTS.Speaking, IELTS.Writing),
                  all_vars(is.na(.))) # all_vars(is.na(.)) means all the variables listed need to be NA
```


#### Remove Variables
We remove variables that we don't use in the model. We remove variables that missing too many data, have almost 1 level, etc.. (details of variable removal criteria are listed in the code)

```{r, eval=FALSE}
# Remove Variables -----------------------------------------------------------------------
# Remove variables about TOEFL, IELTS, Visa Type, and Flag
df %<>% select(-c(TCP1, TCP2, TCP3, TCP4, TCPT, 	
                  TIBL, TIBR, TIBS, TIBT, TIBW, 
                  TOEFL.Listening, TOEFL.Reading, TOEFL.Speaking, 
                  TOEFL.Structure.Written.Expression,
                  IELL, IELO, IELR, IELS, IELW,
                  IELTS.Listening, IELTS.Overall.Band.Score, IELTS.Reading, IELTS.Speaking, IELTS.Writing,
                  Visa.Type, VisaType,
                  MCFlag, InternationalFlag))

# Identify the variables that have all missing values (columns that are entirely N/A) and remove those variables
df %<>% select(-colnames(df[which(lapply(df, function(x) sum(is.na(x))) == nrow(df))]))

# Remove variables based on plot_missing() and redundant variables
plot_missing(df)
df %<>% select(-c(# Contribute nothing
                  tag, ZipCode, Zip, Zipcode, Zip5, Phone,
                  CEEB1, CEEB2, CEEB3, CEEB4, CEEB6, CEEB7, CEEB8, CEEB9, CEEB10, CEEB5,
                  HighSchoolCode, hs.code, HS.Code,
                  TermCode,
                  Decision, # This variable has only 1 level
                  
                  # Too many missing values and duplicated
                  Retained_recode, RoundedGPA,
                  ACTMaxComposite, ACTMaxEnglish, ACTMaxMath, ACTMaxReading, ACTMaxSciReasoning, ACTWritingMax, Super.ACT, Act25, Act75,
                  SAT.R.ERW, SAT.R.Math, Satm25, Satm75, Satv25, Satv75, 
                  SATWRSC, SATVerbal, SATComp,
                  ACTEquivalent,
                  ApplicationDate_Formatted, ConfirmedDate, ConfirmDate_Formatted, DecisionDate_Formatted, DecisionDateFormatted,
                  ACTSci, ACTRdng, ACTMath, ACTEng, ACTComposite, ACTWRSC, # Kept ACTBest
                  
                  ACTChoice, RankPercent, ClassRank, ClassSize, # Rank and size in 2018 missing too much
                  WhichTestBest, Dec,
                  
                  # 2018 data have too little MiamiRanks data
                  MiamiRanks, 
                  FirstSchool, SecondSchool, ThirdSchool, FourthSchool, FifthSchool,SixthSchool, SeventhSchool, EighthSchool, TenthSchool, 
                  
                  ## Variables that 2018 data doesn't have
                  InitialContact, EduNbrhd, Permanent.Home, College.Since.9th.Grade, Primary_Parent_Occupation, Sec_Parent_Occupation,
                  Com.App.Acad.Int,
                  Lang, Math, MeritGPA, DataFrom, FSBDirect,
                  
                  GPAScale, OriginalGPA, GPAOrig, # Keep GPA because it's been re-scale on a 4.0 scale
                  County, CountyCode, # Keep CountyDesc has the least missing values
                  IntlTestScoreThresholdFlag, Intl.Scholarship, ACEFlag, # Related to international students
                  AIDY_Code, ConCode, Harrison, MAI, Geomkt, StudentType, MeritGPAThresholdFlag, # Not sure this vars are about
                  
                  Status, ConfirmCode, HSClust, EER, Division
              ))
```



#### Collapse Variables and Recode Variables
In this step, we collapse variables so that we will have consolidated columns about students information (i.e. collapsing multiple columns about races into 1). We also recode variables and reduce the number of levels in the way that make sense.

```{r, eval=FALSE}
# Identify if the student took SAT or not ---------------------------------
df$SAT <- NA
for (i in 1:nrow(df)) {
  if (is.na(df$SATMath[i]) == TRUE) {
    df$SAT[i] <- "No"
  } else {
    df$SAT[i] <- "Yes"
  }
}
df$SAT = as.factor(df$SAT)

# Remove SATMath
df %<>% select(-SATMath)

# Merging Race Variables --------------------------------------------------
## Merge race to analyze students based on if they are White or not 
levels(df$WH_Race)
levels(df$Race)
levels(df$FullRace)
levels(df$AlmostFullRace)
levels(df$OneRace)

df$WH_Race[df$WH_Race == ""] <- NA
df$Race[df$Race == ""] <- NA
df$FullRace[df$FullRace == ""] <- NA
df$AlmostFullRace[df$AlmostFullRace == ""] <- NA
df$OneRace[df$OneRace == ""] <- NA

# Create columns Race_WH to identify if students are White
df$Race_WH <- NA

levels(df$Race_WH) <- c(levels(df$Race_WH), c("Yes", "No", "Unknown")) # Add new level

df$Race_WH[df$WH_Race == "WH" | df$Race %in% c("White", "WH", "5") | 
              df$FullRace %in% c("WH", "White") | df$AlmostFullRace == "WH" | 
              df$OneRace %in% c("WH", "White")] <- "Yes"

df$Race_WH[df$OneRace %in% c("UK", "Unknown") | df$Race %in% c("UK", "8") | df$FullRace == "UK"] <- "Unknown"
df$Race_WH[is.na(df$Race_WH) == T] <- "No"

df$Race_WH = as.factor(df$Race_WH)

## Remove all race variables except for Race_WH
df %<>% select(-c(Race, AI_Race, AS_Race, BL_Race, HS_Race,
                  PI_Race, WH_Race, OneRace, FullRace, 
                  FullEthn.Race, AlmostFullRace, FullEthn,
                  Ethn_HS_YN, Hispanic))

## Merge 2 Special Consideration columns and only replace N/A values with the other columns value
df$SpecialConsideration[df$SpecialConsideration == ""] <- NA
df$Special.Consideration[df$Special.Consideration == ""] <- NA
df["SpecialConsideration"] = coalesce(df$SpecialConsideration, df$Special.Consideration)
df %<>% select(-Special.Consideration) # Remove one column

levels(df$SpecialConsideration) <- c(levels(df$SpecialConsideration), c("No", "Yes")) # Add new level ("No")
df$SpecialConsideration[is.na(df$SpecialConsideration == T)]  <- "No" # Change NA values to No
df$SpecialConsideration[df$SpecialConsideration != "No"] <- "Yes"
df$SpecialConsideration <- droplevels(df$SpecialConsideration)

# Fix Citizenship ---------------------------------------------------------
levels(df$Citizen)
levels(df$Citizen) <- c(levels(df$Citizen), "Unknown") # Add new level "Unknown"
df$Citizen[is.na(df$Citizen == T) | df$Citizen %in% c("","D")]  <- "Unknown"
df$Citizen <- droplevels(df$Citizen)

# Remove citizenship2 col
df %<>% select(-c(Citizenship, Citizenship2))

# Fix Parent Edu Level ----------------------------------------------------
df$Parent.1.Education.Level[df$Parent.1.Education.Level == ""]  <- NA
df$Parent.2.Educational.Level[df$Parent.2.Educational.Level == ""]  <- NA
df$Parent1Degree[df$Parent1Degree == ""]  <- NA
df$Parent2Degree[df$Parent2Degree == ""]  <- NA

# Identify if one of the parents have bachelor degree or above
df$Parent_College <- NA
for (i in 1:nrow(df)) {
  if (df$Parent.1.Education.Level[i] %in% c("Graduate school", "Graduated from college/university") | 
      df$Parent1Degree[i] %in% "College" | 
      df$Parent.2.Educational.Level[i] %in% c("Graduate school", "Graduated from college/university") |
      df$Parent2Degree[i] %in% "College") {
    df$Parent_College[i] <- "Yes"
  } else if ((is.na(df$Parent.1.Education.Level[i])) == T & (is.na(df$Parent.2.Educational.Level[i])) == T &
              (is.na(df$Parent1Degree[i])) == T & (is.na(df$Parent2Degree[i])) == T) {
    df$Parent_College[i] <- "Unknown"
  } else {
    df$Parent_College[i] <- "No"
  }
}

df$Parent_College = as.factor(df$Parent_College)

# Remove parent_level and parent_degree cols
df %<>% select(-c(Parent.1.Education.Level, Parent.2.Educational.Level,
                  Parent1Degree, Parent2Degree))

# Collapse Major ----------------------------------------------------------
# Read in major description
major_code = read_excel("Major Codes and Descriptions.xlsx")

# Merge 2 df, keep the left one
df = left_join(df, major_code, by = c("Major" = "STVMAJR_CODE"))
for (i in 1:nrow(df)) {
  if(is.na(df$STVMAJR_DESC[i]) == TRUE) {
    df$STVMAJR_DESC[i] <- df$Major[i]
  }
}

df = select(df, -Major)

names(df)[names(df) == 'STVMAJR_DESC'] <- 'Major' # Rename variable

# Coding "56" and "Undeclared - XX" as Undeclared 
df$Major <- str_replace_all(string = df$Major, pattern = "56", replacement = "Undeclared")
df$Major <- str_replace_all(string = df$Major, pattern = "[A-Z]{2}56", replacement = "Undeclared")
df$Major <- str_replace_all(string = df$Major, pattern = "[A-Z]{2}Undeclared", replacement = "Undeclared")
df$Major <- str_replace_all(string = df$Major, pattern = "Undeclared.*", replacement = "Undeclared")

df$Major[df$Major %in% c("Strategic Communication", "Communication Design", "Communication Pre-Major")] <- "Communication"
df$Major[df$Major %in% c("Management Information Systems", "Information Systems")] <- "Information Systems and Analytics"


# Sort top10 majors
head(sort(table(df$Major), decreasing = T), 10)

top10_major <- head(sort(table(df$Major), decreasing = T), 10) %>% 
  as.data.frame()

for (i in 1: nrow(df)) {
  if ((df$Major[i] %in% top10_major$Var1) == FALSE) {
    df$Major[i] <- "Others"
  } else if ((df$Major[i] %in% top10_major$Var1) == TRUE) {
    df$Major[i] <- df$Major[i]
  }
}

df$Major %<>% as.factor()
levels(df$Major)

# Fixing SuppMajors -------------------------------------------------------
# Decide if the students have one or multiple majors
levels(df$SuppMajor1)
table(is.na(df$SuppMajor2))
table(is.na(df$SuppMajor3))

df$SuppMajor1[df$SuppMajor1 == ""] <- NA
df$SuppMajor2[df$SuppMajor2 == ""] <- NA
df$SuppMajor3[df$SuppMajor3 == ""] <- NA

df$OneMajor <- NA
for (i in 1:nrow(df)) {
  if (is.na(df$SuppMajor1[i]) == FALSE & is.na(df$SuppMajor2[i]) == TRUE & is.na(df$SuppMajor3[i]) == TRUE) {
    df$OneMajor[i] <- "Yes" # only one major
  } else if (is.na(df$SuppMajor1[i]) == TRUE) {
    df$OneMajor[i] <- "Unknown"
  } else {
    df$OneMajor[i] <- "No" # more than one major
  }
}

df$OneMajor = as.factor(df$OneMajor)

# Remove suppMajor1, suppMajor2, suppMajor3 
df %<>% select(-c(SuppMajor1, SuppMajor2, SuppMajor3))

# Fix Date ----------------------------------------------------------------
df$ConfirmDate %<>% ymd()
df$ApplicationDate = as.Date(df$ApplicationDate, format = "%m/%d/%Y")
df$DecisionDate = as.Date(df$DecisionDate, format = "%m/%d/%Y")

# Find the difference between ApplicationDate and DecisionDate
x<-interval(ymd(df$ApplicationDate), ymd(df$DecisionDate))
x<-x %/% days(1)
df$DecisionLength<-x
df$DecisionLength = ifelse(df$DecisionLength < 0, 0, df$DecisionLength)

# Remove ApplicationDate, ConfirmDate and DecisionDate
df %<>% select(-c(ApplicationDate, DecisionDate, ConfirmDate))

# Recode Variables --------------------------------------------------------
# Recode FirstGen 
df$FirstGen = ifelse(is.na(df$FirstGen) | df$FirstGen == "", "No", "Yes")
df$FirstGen = as.factor(df$FirstGen)
str(df$FirstGen)

# Recode Bridges
df$Bridges = ifelse(is.na(df$Bridges) | df$Bridges == "", "No", "Yes")
df$Bridges = as.factor(df$Bridges)
str(df$Bridges)

# Recode AlumniConnection
levels(df$AlumniConnection)
levels(df$AlumniConnection) <- c(levels(df$AlumniConnection), c("Yes", "No")) # Add new levels
df$AlumniConnection[(is.na(df$AlumniConnection) == T) | (df$AlumniConnection == "")] <- "No"
df$AlumniConnection[df$AlumniConnection != "No"] <- "Yes"
df$AlumniConnection <- droplevels(df$AlumniConnection)

# Recode DecisionType
levels(df$DecisionType) <- c(levels(df$DecisionType), c("Others", "Unknown")) # Add new levels
df$DecisionType[df$DecisionType == "" | is.na(df$DecisionType == T)]  <- "Unknown" # Change "" and NA values to Unknown
df$DecisionType[df$DecisionType %in% c("DN", "DQ", "HN", "HQ", "HY", "N", "S", "SQ", "SY")]  <- "Others"
df$DecisionType <- droplevels(df$DecisionType)
str(df$DecisionType)

# Recode ON (Other Notion Score)
df$ON = as.factor(df$ON)
levels(df$ON) <- c(levels(df$ON), c("Unknown")) # Add new level
df$ON[is.na(df$ON) == T]  <- "Unknown" # Change NA values to Unknown
df$ON <- droplevels(df$ON)
df = select(df, -ON)

# Recode HsType
levels(df$HsType) <- c(levels(df$HsType), c("Others")) # Add new level
df$HsType[df$HsType == "1"]  <- "Public"
df$HsType[df$HsType == "2"]  <- "Private Secular"
df$HsType[df$HsType == "3"]  <- "Religious"
df$HsType[df$HsType == "4"]  <- "Religious"
df$HsType[df$HsType %in% c("Charter", "Home School")]  <- "Others"
df$HsType[is.na(df$HsType == T) | df$HsType == ""]  <- "Unknown"
df$HsType <- droplevels(df$HsType)

# Recode Housing variable
levels(df$Housing) <- c(levels(df$Housing), c("Unknown")) # Add new level
df$Housing[is.na(df$Housing) == T] <- "Unknown"

# Recode StateResidency
df$StateResidency[df$StateResidency == "Z"] <- "N"
df$StateResidency <- droplevels(df$StateResidency)

# Recode retained (our target variable)
names(df)[names(df) == 'retained'] <- 'Target' # Rename variable as "Target"
df$Target = as.factor(df$Target)
levels(df$Target) <- c(levels(df$Target), "Yes") # Add new level ("Yes")
levels(df$Target) <- c(levels(df$Target), "No") # Add new level ("No")
df$Target[df$Target == "1"]  <- "No"
df$Target[df$Target == "0"]  <- "Yes" 
df$Target <- droplevels(df$Target)

# Filter rows missing Target
df %<>% filter(is.na(df$Target) != T)

# Fix DisciplinaryQuestions -------------------------------------------------
# Identify if the students ever flagged for disciplinary questions
df$Question[df$Question == ""]  <- NA
df$DisciplinaryQuestion1[df$DisciplinaryQuestion1 == ""]  <- NA

df$Disciplinary <- NA
levels(df$Target) <- c(levels(df$Target), c("Yes", "No")) # Add new levels
df$Disciplinary[(is.na(df$Question) == TRUE) & (is.na(df$DisciplinaryQuestion1) == TRUE)] <- "No"
df$Disciplinary[is.na(df$Question) == FALSE | is.na(df$DisciplinaryQuestion1) == FALSE] <- "Yes"
df$Disciplinary = as.factor(df$Disciplinary)

# Remove Question, DisciplinaryQuestion1
df %<>% select(-c(Question, DisciplinaryQuestion1))

# Fix NationDesc ----------------------------------------------------
# Recode NationDesc
df$NationDesc[is.na(df$NationDesc == T)]  <- "United States"

# Identify US nation or non-US
levels(df$NationDesc)
df$Nation <- NA

for (i in 1:nrow(df)) {
  if (df$NationDesc[i] == "United States" ){
    df$Nation[i] <- "US"
  } else {
    df$Nation[i] <- "Non-US"
  }
}
df$Nation = as.factor(df$Nation)

# Remove NationDesc
df %<>% select(-NationDesc)

# Fix HomeState -----------------------------------------------------------
levels(df$HomeState)

# Top 5 states: OH    IL    MI    IN    PA
head(sort(table(df$HomeState), decreasing = T), 5)

levels(df$HomeState) <- c(levels(df$HomeState), c("Unknown")) # Add new level
df$HomeState[df$HomeState == "" | is.na(df$HomeState) == T] <- "Unknown"
df$HomeState = as.factor(df$HomeState)
df$HomeState <- droplevels(df$HomeState)

# Remove
df %<>% select(-c(OhioCountyRegion, 
                  USStateRegion, CountyDesc))

# Fix HighSchoolState -------------------------------------------------------
levels(df$HighSchoolState)

# Top 5 states: OH    IL    IN    MI    PA
head(sort(table(df$HighSchoolState), decreasing = T), 5)
levels(df$HighSchoolState) <- c(levels(df$HighSchoolState), c("Unknown")) # Add new level
df$HighSchoolState[df$HighSchoolState == "" | is.na(df$HighSchoolState) == T] <- "Unknown"
df$HighSchoolState = as.factor(df$HighSchoolState)
df$HighSchoolState <- droplevels(df$HighSchoolState)

# Fix Concentration -------------------------------------------------------
levels(df$Concentration)

# Top concentration:
head(sort(table(df$Concentration), decreasing = T), 5)

levels(df$Concentration) <- c(levels(df$Concentration), c("Unknown")) # Add new level
df$Concentration[df$Concentration == "" | is.na(df$Concentration) == T] <- "Unknown"
df$Concentration <- droplevels(df$Concentration)
```



#### Create Dummies
We create dummies for categorical variables. For variables that have more than 20 levels, we will create dummies for the top 5-10.

```{r, eval=FALSE}
# Create Dummies ----------------------------------------------------------
introduce(df)
data.summary(df)

df$DecisionType <- relevel(df$DecisionType,"Others")
df$Major <- relevel(df$Major,"Others")
df$HsType <- relevel(df$HsType,"Others")

# Dummy for top levels in HomeState, HighSchoolState, Concentration, 
# Housing, ON, Race_WH, Citizen, Parent_College
## HomeState
df$HomeState_OH = ifelse(df$HomeState == "OH", 1, 0)
df$HomeState_IL = ifelse(df$HomeState == "IL", 1, 0)
df$HomeState_MI = ifelse(df$HomeState == "MI", 1, 0)
df$HomeState_IN = ifelse(df$HomeState == "IN", 1, 0)
df$HomeState_PA = ifelse(df$HomeState == "PA", 1, 0)
df = select(df, -HomeState)

## HighSchoolState
df$HighSchoolState_OH = ifelse(df$HighSchoolState == "OH", 1, 0)
df$HighSchoolState_IL = ifelse(df$HighSchoolState== "IL", 1, 0)
df$HighSchoolState_MI = ifelse(df$HighSchoolState == "MI", 1, 0)
df$HighSchoolState_IN = ifelse(df$HighSchoolState == "IN", 1, 0)
df$HighSchoolState_PA = ifelse(df$HighSchoolState == "PA", 1, 0)
df = select(df, -HighSchoolState)

## Concentration
df$Concentration_BB = ifelse(df$Concentration == "BB", 1, 0)
df$Concentration_PM = ifelse(df$Concentration == "PM", 1, 0)
df = select(df, -Concentration)

## Housing
df$Housing_ON = ifelse(df$Housing == "On Campus", 1, 0)
df = select(df, -Housing)

## Race_WH
df$Race_WH_Yes = ifelse(df$Race_WH == "Yes", 1, 0)
df = select(df, -Race_WH)

## Citizen
df$Citizen_Y = ifelse(df$Citizen == "Y", 1, 0)
df = select(df, -Citizen)

## OneMajor
df$OneMajor_Yes = ifelse(df$OneMajor == "Yes", 1, 0)
df = select(df, -OneMajor)

df <- dummy_columns(df, select_columns = c("Gender", "StateResidency", "FirstGen", "AlumniConnection", "ApplicationType",
                                           "SpecialConsideration", "DecisionType", "Major", "HsType",
                                           "Bridges", "SAT", "Parent_College",
                                           "Disciplinary", "Nation"),
                    remove_first_dummy = TRUE, 
                    remove_selected_columns = TRUE)
```


#### Imputation
We use `plot_missing(df)` to identify the missing values. We impute the missing values and create missing indicator for variables that are missing more than 10%. We finish up by cleaning the column names so that they won't cause errors when building models and save the cleaned data into a .RDS file.

```{r, eval=FALSE}
# Imputation --------------------------------------------------------------
plot_missing(df)

df$GPA[is.na(df$GPA)]<-median(df$GPA, na.rm=TRUE)
df$AcadRS[is.na(df$AcadRS)]<-median(df$AcadRS, na.rm=TRUE)
df$M_DecisionLength<-ifelse(is.na(df$DecisionLength), 1, 0)
df$DecisionLength[is.na(df$DecisionLength)]<-median(df$DecisionLength, na.rm=TRUE)

plot_missing(df)

# Tidy column names
names(df) <- gsub(" ", "_", names(df))

saveRDS(df, "domestic.clean.RDS")
```


#### Split to Training/Validation
We split the data into training and validation set with a ratio of 80/20. We choose to split the data in a way that it is stratified by year (i.e. some of every year in the training data) because we think that by including every year in the data set, it will help the models to recognize patterns and will predict better.

```{r, eval=FALSE}
pacman::p_load(tidyverse, DataExplorer, ROCR, pROC, caret, gbm, ranger, doParallel, xgboost)

# Read in RDS file
df = readRDS("domestic.clean.RDS")

# Make sure the reference level is "No"
df$Target <-relevel(df$Target, ref="No")

# Split data
set.seed(13)
trainIndex<-createDataPartition(df$Target, p=0.8, list=FALSE, times=1)

library(tidyverse)
training<-df[trainIndex,]
training = select(training, -DateFrom)

valid<-df[-trainIndex,]
valid = select(valid, -DateFrom)

saveRDS(valid, "valid.RDS")
saveRDS(training, "training.RDS")
saveRDS(trainIndex, "trainIndex.RDS")
```



### Modeling {.tabset}


#### Model 1-3: Logistic Regression Models
We created three logistic models: the full logistic model, the stepwise logistic model with Linear Terms and the stepwise logistic model with iterations. The full logistic model using all the variables to build the model. The stepwise with linear terms model uses the lowest AIC to get the variables that are more statistically important to the predict. The stepwise with iteration model uses the iteration of all the variables in the stepwise linear model to build the model. 

```{r,eval=FALSE}
ctrl<-trainControl(method="none", summaryFunction = twoClassSummary, classProbs = TRUE, savePredictions = TRUE)

########### The full logistic model ########### 

lrfull<-train(Target~., data=training, method="glm", family="binomial", metric="ROC", trControl=ctrl)

########### Stepwise with Linear Terms ########### 

lrstep<-train(Target~., data=training, method="glmStepAIC", direction="both", metric="ROC", trControl=ctrl, trace=0)

########### Stepwise with Interations ###########

lrstep$finalModel$formula

f<-formula(Target ~ (GPA + ACTBest + AcadRS +HomeState_OH + HighSchoolState_IL + 
    HighSchoolState_MI + Concentration_PM + Housing_ON + Citizen_Y + 
    FirstGen_Yes + AlumniConnection_No + ApplicationType_OF + 
    ApplicationType_OM + SpecialConsideration_Yes + DecisionType_Unknown + 
    Major_Accountancy + Major_Finance + Major_Zoology + HsType_Private_Secular + 
    HsType_Public + HsType_Religious + Bridges_Yes + SAT_Yes)^2)

full<-glm(f, data=training, family="binomial")
null<-glm(Target~1, data=training, family="binomial")
step2<-step(null, list(lower=formula(null), upper=formula(full)), data=training, direction="both", trace=0)

```



#### Model 4: Random Forest Model
In the random forest model, we use cross validation and set k=10 folds (10 cross validation samples). We set the number of variables subset at each split (mtry) to 2, 5, 10, 19, set split rule to the impurity measure, and set minimum number of observations a node has to split to 300, 350, 370. We also create 1000 bootstrap samples (num.trees) and use the AUC to evaluate the model.

```{r,eval=FALSE}
y<-training$Target
x<-select(training, -Target)

set.seed(13)
cvindx<-createFolds(trainIndex, k=10, returnTrain = TRUE)
ctrl <- trainControl(method="cv", index=cvindx, summaryFunction = twoClassSummary, classProbs = TRUE)

library(ranger)
tunegrid <- expand.grid(
     .mtry = c(2, 5, 10, 19),
     .splitrule = "gini",
    .min.node.size = c(300, 350, 370)
  )


library(doParallel)
cl <- makePSOCKcluster(7)
registerDoParallel(cl)

rforest<-train(x=x, y=y, method="ranger", tuneGrid=tunegrid, metric="ROC",
               num.trees=1000, importance="impurity", trControl=ctrl )
stopCluster(cl)
rforest
```



#### Model 5: Boosted Tree Model
We set the number of trees as 100-250, shrinkage as 0.1, 0.05, 0.01 to run the model.

```{r, eval=FALSE}
library(gbm)
set.seed(13)

Grid <- expand.grid(n.trees = seq(100,250,50), interaction.depth = c(10, 20, 30), shrinkage = c(0.1, 0.05, 0.01), n.minobsinnode=c(15, 20, 25))

cl <- makePSOCKcluster(7) #starts the cluster
registerDoParallel(cl)

gb.tree <- train(Target~., 
                 data=training, 
                 method = 'gbm', 
                 trControl=ctrl, 
                 tuneGrid=Grid, 
                 metric='ROC')

stopCluster(cl)
gb.tree
```



#### Model 6-7: Neural Network Models
There are two neural network models. One with the terms from logistic regression and the other is with the terms from random forest. For the neural network with terms from logistic regression model, we use terms in the 
step wise logistic regression with linear terms. For the neural network with terms from random forest model, we sort and use the top 30 most important variables from the random forest model to build the neural network model.

```{r,eval=FALSE}
### set up model
library(nnet)

trainIndex<-seq(1:nrow(training))
cvindx<-createFolds(trainIndex, k=10, returnTrain = TRUE)
ctrl <- trainControl(method="cv", index=cvindx, summaryFunction = twoClassSummary, classProbs = TRUE)

tunegrid<-expand.grid( .size=1:10, .decay= c(0, 0.1, 0.5))
maxSize<-max(tunegrid$.size)

numWts<-500

##### NN with terms from Logistic Regression #####

terms<-names(lrstep$finalModel$coefficients)

terms<-terms[-1]

library(doParallel)

cl <- makePSOCKcluster(6) #Starts the parallel computing
registerDoParallel(cl)

nnetFit<-train(x=training[,terms], y=training$Target, 
               method="nnet", 
               metric="ROC", 
               linout=FALSE,
               preProcess = c("range"), 
               tuneGrid = tunegrid, 
              
               trace=FALSE,
               maxit=100,
               MaxNWts=numWts,
               trControl=ctrl)


stopCluster(cl) 
nnetFit


##### NN with terms from Random Forest #####

library(randomForest) 
library(caret)
varI<-varImp(rforest)
var<-as.data.frame(varI$importance)
var <- cbind(rownames(var), data.frame(var, row.names=NULL))

var <- var[order(-var$Overall), ]
terms.rf<-var$`rownames(var)`[1:30, drop=TRUE]

x<-training[,terms.rf] #look at the head here, Target was still in this data
y <- training$Target

cl <- makePSOCKcluster(6) #Starts the parallel computing
registerDoParallel(cl)

nnetFit.rf<-train(x=x, y=y, 
               method="nnet", 
               metric="ROC", 
               linout=FALSE,
               preProcess = c("range"), 
               tuneGrid = tunegrid, 
               
               trace=FALSE,
               maxit=100,
               MaxNWts=numWts,
               trControl=ctrl)


stopCluster(cl) 
nnetFit.rf

```


```{r, eval=FALSE}
# Save all models
saveRDS(lrfull,"lrfull.RDS")
saveRDS(lrstep,"lrstep.RDS")
saveRDS(step2, "step2.RDS")
saveRDS(rforest,"rforest.RDS")
saveRDS(gb.tree,"gb.tree.RDS")
saveRDS(nnetFit,"nnetFit.RDS")
saveRDS(nnetFit.rf,"nnetFitRF.RDS")
```
